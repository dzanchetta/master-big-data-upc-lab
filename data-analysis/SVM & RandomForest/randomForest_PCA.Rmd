---
title: "Random Forest_PCA"
author: "Lais Silva Almeida Zanchetta, Daniel Ferreira Zanchetta"
date: "5/2/2020"
output: html_document
---

# Ramdon Forest - Pre-proceso con PCA:
```{r}
#Pre-proceso
library(dplyr)
library(tidyr)
library(caret)

#Leemos el fichero y eliminamos las dos primeras variables, siguiendo las recomendaciones en el Musk2.info
musk <- read.table(file.choose(),sep = ",") %>% select(-c(V1,V2))

colnames(musk) <- c(paste0("f",1:166), "class")

#PCA
library(FactoMineR)
pca.musk <- PCA(musk,quali.sup=167, scale.unit = TRUE)
n = 25 #defino numero de componentes significativas
pca.musk <- PCA(musk, ncp=n, quali.sup=167, scale.unit = TRUE)
musk.pca <- (cbind(as.data.frame(pca.musk$ind$coord),musk[167]))

musk <- musk.pca
#Pasamos la variable class a factor
musk$class <- as.factor(musk$class)
#Normalizamos las variables numericas utilizando el metodo scale y center
musk <- musk %>% mutate_if(is.numeric, scale, center = T, scale = T)

set.seed(7)
#Separamos Musk en Data Frame de training y testing, siendo que training contiene 70% de los registros
#Intentamos con el createDataPartition del caret pero no nos ha servido pues no genera muestras aleatorias
#tran_sample <- createDataPartition(y = musk$class, p= 0.7, list = FALSE)
tran_sample <- sample(seq_len(nrow(musk)), size = nrow(musk) * 0.7)
train_musk   <- musk[tran_sample, ] #[ELIMINAR] aqui estou pegando as linhas do arquivo original de acordo com as posiçoes aleatorias geradas em tran_sample 
test_musk    <- musk[-tran_sample, ] #[ELIMINAR] aqui estou pegando as linhas que nao constam no vetor tran_sample

# Aplicando Random Forest

library(randomForest)

```
# Random Forest con 100 arboles - Error real 4.34%
```{r}
# Random Forest con 100 arboles para crecer
musk.randomfor1 <- randomForest(class ~., data = train_musk, ntree = 100)

# Error estimado - OOB estimate of error rate: 4.85%
musk.randomfor1

# Error real - 4.34%
pred_randomfor1 <- predict(musk.randomfor1, newdata=test_musk)

confusion.matrix.rf <- table(test_musk$class, pred_randomfor1)

confusion.matrix.rf

(1-sum(diag(confusion.matrix.rf))/sum(confusion.matrix.rf))*100

# Porcentaje por clase en la matriz de confusión resultante
prop.table(confusion.matrix.rf, 1)

# Porcentaje total de predicciones correctas - 95.65%
sum(diag(confusion.matrix.rf))/sum(confusion.matrix.rf)

# Error de teste real - 4,34%
round(100*(1-sum(diag(confusion.matrix.rf))/sum(confusion.matrix.rf)),2)
```
# Random Forest con 200 arboles - Tiene un error de teste mas grande que con 100 arboles - Error real 4.19%
```{r}
# Random Forest con 200 arboles para crecer
musk.randomfor2 <- randomForest(class ~., data = train_musk, ntree = 200)

# Error estimado - OOB estimate of error rate: 4.83%
musk.randomfor2

# Error real - 4.19%
pred_randomfor2 <- predict(musk.randomfor2, newdata=test_musk)

confusion.matrix.rf <- table(test_musk$class, pred_randomfor2)

confusion.matrix.rf

(1-sum(diag(confusion.matrix.rf))/sum(confusion.matrix.rf))*100

# Porcentaje por clase en la matriz de confusión resultante
prop.table(confusion.matrix.rf, 1)

# Porcentaje total de predicciones correctas - 95.80%
sum(diag(confusion.matrix.rf))/sum(confusion.matrix.rf)

# Error de teste real - 4,19%
round(100*(1-sum(diag(confusion.matrix.rf))/sum(confusion.matrix.rf)),2)
```
# Random Forest con upsample de la clase menos representada (Musk) - ntree = 100 (mejor que con 250) - Error real 4.39%
```{r}
# Musk upsample con 100 arboles
(muestra.musk <- table(train_musk$class)["1"])
(muestra.nomusk <- table(train_musk$class)["0"])

set.seed(7)
musk.randomfor3 <- randomForest(class ~ ., data=train_musk, ntree=100, proximity=FALSE, 
                          sampsize=c("1"=735, "0"=650), strata=train_musk$class)

# Error estimado - OOB estimate of error rate: 4.79%
musk.randomfor3

# Error real - 4.79%
pred_randomfor3 <- predict(musk.randomfor3, test_musk, type="class")

confusion.matrix.rf <- table(test_musk$class, pred_randomfor3)

confusion.matrix.rf

(1-sum(diag(confusion.matrix.rf))/sum(confusion.matrix.rf))*100

# Porcentaje por clase en la matriz de confusión resultante
prop.table(confusion.matrix.rf, 1)

# Porcentaje total de predicciones correctas - 98.78%
sum(diag(confusion.matrix.rf))/sum(confusion.matrix.rf)

# Error de teste real - 4.79%
round(100*(1-sum(diag(confusion.matrix.rf))/sum(confusion.matrix.rf)),2)

# Plot error rate en funcción del numero de arboles utilizados: 
# Negro = out of bag (OOB)
# Rojo = label 1 ('Musk')
# Verde  = label 2 ('NonMusk')
plot(musk.randomfor3, main = "Modelo 3 Random Forest")

legend("topright", legend=c("OOB", "Musk", "NonMusk"),    
       pch=c(1,1), col=c("black","red","green"))

# Cuales son las variables utilizadas en la forest y cuantas veces son utilizadas las variables en la predicción
varUsed(musk.randomfor3, by.tree=FALSE, count = TRUE)
```
# Random Forest con upsample de la clase menos representada (Musk) - ntree = 250 
```{r}
# Musk upsample con 250 arboles
(muestra.musk <- table(train_musk$class)["1"])
(muestra.nomusk <- table(train_musk$class)["0"])

set.seed(7)
musk.randomfor4 <- randomForest(class ~ ., data=train_musk, ntree=250, proximity=FALSE, 
                          sampsize=c("1"=735, "0"=650), strata=train_musk$class)

# Error estimado - OOB estimate of error rate: 4.59%
musk.randomfor4

# Error real - 4.44%
pred_randomfor4 <- predict(musk.randomfor4, test_musk, type="class")

confusion.matrix.rf <- table(test_musk$class, pred_randomfor4)

confusion.matrix.rf

(1-sum(diag(confusion.matrix.rf))/sum(confusion.matrix.rf))*100

# Porcentaje por clase en la matriz de confusión resultante
prop.table(confusion.matrix.rf, 1)

# Porcentaje total de predicciones correctas - 94.89%
sum(diag(confusion.matrix.rf))/sum(confusion.matrix.rf)

# Error de teste real - 4,44%
round(100*(1-sum(diag(confusion.matrix.rf))/sum(confusion.matrix.rf)),2)

# Plot error rate en funcción del numero de arboles utilizados: 
# Negro = out of bag (OOB)
# Rojo = label 1 ('Musk')
# Verde  = label 2 ('NonMusk')
plot(musk.randomfor4, main = "Modelo 4 Random Forest")

legend("topright", legend=c("OOB", "Musk", "NonMusk"),    
       pch=c(1,1), col=c("black","red","green"))

# Cuales son las variables utilizadas en la forest y cuantas veces son utilizadas las variables en la predicción
varUsed(musk.randomfor4, by.tree=FALSE, count = TRUE)
```
# Optimización del Random Forest guiada pelo OOB
```{r}
# Optimización de la cantidad de arboles guiada por el OOB
(ntrees <- round(10^seq(1,3,by=0.4)))

# Estructura para almacenar los resultados parciales 
randomfor.results <- matrix (rep(0,2*length(ntrees)),nrow=length(ntrees))
colnames (randomfor.results) <- c("ntrees", "OOB")
randomfor.results[,"ntrees"] <- ntrees
randomfor.results[,"OOB"] <- 0

ii <- 1

for (nt in ntrees)
{ 
  print(nt)
  
  musk.randomfor5 <- randomForest(class ~ ., data=train_musk, ntree=nt, proximity=FALSE, 
                          sampsize=c("1"=735, "0"=650), strata=train_musk$class)
  
  # get the OOB
  randomfor.results[ii,"OOB"] <- musk.randomfor5$err.rate[nt,1]
  
  ii <- ii+1
}

randomfor.results

# Plot error rate en funcción del numero de arboles utilizados: 
# Negro = out of bag (OOB)
# Rojo = label 1 ('Musk')
# Verde  = label 2 ('NonMusk')
plot(musk.randomfor5, main = "Modelo 5 Random Forest")

legend("topright", legend=c("OOB", "Musk", "NonMusk"),    
       pch=c(1,1), col=c("black","red","green"))

# Cuales son las variables utilizadas en la forest y cuantas veces son utilizadas las variables en la predicción
varUsed(musk.randomfor5, by.tree=FALSE, count = TRUE)

# Encontrando el ntree que genera la tasa de error estimada más baja - ntree=398

lowest.OOB.error <- as.integer(which.min(randomfor.results[,"OOB"]))
(ntrees.bestresult <- randomfor.results[lowest.OOB.error,"ntrees"])

## Now refit the RF with the best value of 'ntrees'

musk.randomfor6 <- randomForest(class ~ ., data=train_musk, ntree=ntrees.bestresult, proximity=FALSE, 
                         sampsize=c("1"=735, "0"=650), strata=train_musk$class)

# Error estimado - OOB estimate of error rate: 4.44%
musk.randomfor6

# Error real - 4.44%
pred_randomfor6 <- predict(musk.randomfor6, test_musk, type="class")

confusion.matrix.rf <- table(test_musk$class, pred_randomfor6)

confusion.matrix.rf

(1-sum(diag(confusion.matrix.rf))/sum(confusion.matrix.rf))*100

# Porcentaje por clase en la matriz de confusión resultante
prop.table(confusion.matrix.rf, 1)

# Porcentaje total de predicciones correctas - 96.11%
sum(diag(confusion.matrix.rf))/sum(confusion.matrix.rf)

# Error de teste real - 3,89%
round(100*(1-sum(diag(confusion.matrix.rf))/sum(confusion.matrix.rf)),2)

# Importancia de las variables: observamos que, en este caso, las variables que más influyen en este modelo son f36, f163, f126 y f95
importance(musk.randomfor6)
varImpPlot(musk.randomfor6)

# Plot error rate en funcción del numero de arboles utilizados: 
# Negro = out of bag (OOB)
# Rojo = label 1 ('Musk')
# Verde  = label 2 ('NonMusk')
plot(musk.randomfor6, main = "Modelo 6 RF")

legend("topright", legend=c("OOB", "Musk", "NonMusk"),    
       pch=c(1,1), col=c("black","red","green"))

# Cuales son las variables utilizadas en la forest y cuantas veces son utilizadas las variables en la predicción
varUsed(musk.randomfor6, by.tree=FALSE, count = TRUE)

barplot(varUsed(musk.randomfor6, by.tree=FALSE, count = TRUE))
```