---
title: "Exercise ML - SVM and Random Forest"
output: html_notebook
---

## Pre-processing
```{r}
library(dplyr)
library(tidyr)

#Leemos el fichero y eliminamos las dos primeras variables, siguiendo las recomendaciones en el Musk2.info
musk <- read.table(file.choose(),sep = ",") %>% select(-c(V1,V2))

colnames(musk) <- c(paste0("f",1:166), 'class')

#Pasamos la variable class a factor
musk$class <- as.factor(musk$class)

#Normalizamos las variables numericas utilizando el metodo scale y center
musk <- musk %>% mutate_if(is.numeric, scale, center = T, scale = T)


set.seed(7)
#Separamos Musk en Data Frame de training y testing, siendo que training contiene 70% de los registros
#Intentamos con el createDataPartition del caret pero no nos ha servido pues no genera muestras aleatorias
#tran_sample <- createDataPartition(y = musk$class, p= 0.7, list = FALSE)
tran_sample <- sample(seq_len(nrow(musk)), size = nrow(musk) * 0.7)
train_musk   <- musk[tran_sample, ] #[ELIMINAR] aqui estou pegando as linhas do arquivo original de acordo com as posiçoes aleatorias geradas em tran_sample 
test_musk    <- musk[-tran_sample, ] #[ELIMINAR] aqui estou pegando as linhas que nao constam no vetor tran_sample
```

## SVM con Linear Kernel
```{r}
library(e1071)

#Para el primer modelo utilizaremos: 
# - type = C-classification --> utilizado para clasificación binaria
# - cost = 10
# - scale = FALSE --> utilizado para que el svm() no escale las features para que tengan media 0 o standard deviation 1
modelSVMlinear = svm(class~., data = train_musk, type = 'C-classification', kernel = 'linear', cost=10, scale=FALSE)

#plot no esta bien, hay que investigar como hacer un plot
plot(modelSVMlinear,train_musk, formula=class)

# Decision.value --> Logical controlling whether the decision values of all binary classifiers computed in multiclass classification shall be computed and returned
pred <- predict(modelSVMlinear, newdata = test_musk,type="class", decision.values = TRUE)

#Test Error - 3.93%
cm <- table(Truth=test_musk$class, Pred=pred)
(1-sum(diag(cm))/sum(cm))*100

summary(modelSVMlinear)
#556 support vector - 306 son 0 y 250 son 1

#Para el segundo modelo utilizaremos: 
# - type = C-classification --> utilizado para clasificación binaria
# - cost = 0.1
# - scale = FALSE --> utilizado para que el svm() no escale las features para que tengan media 0 o standard deviation 1
modelSVMlinear2 = svm(class~., data = train_musk, type = 'C-classification', kernel = 'linear', cost=0.1, scale=FALSE)

pred2 <- predict(modelSVMlinear2, newdata = test_musk,type="class", decision.values = TRUE)

#Test Error - 5.30%
cm2 <- table(Truth=test_musk$class, Pred=pred2)
(1-sum(diag(cm2))/sum(cm2))*100

summary(modelSVMlinear)
#709 support vector - 375 son 0 y 334 son 1

#Ahora utilizamos la función tune() que esta incluida en el paquete e1071, para realizar cross-validation. Por defecto tune() utiliza 10-fold cross-validation, lo que creemos que sea ideal para realizar este modelo (tunecontrol=tune.control(cross=10))
set.seed(1)
tune.out <- tune(svm,class~., data = train_musk, type = 'C-classification', kernel = 'linear',ranges=list(cost=c(0.001, 0.01, 1.5, 5, 10, 100)))

summary(tune.out)
#El modelo con cost = 1.5 ha tenido mejor resultado (error = 0.04872477 dispersion= 0.009100116)

#Ahora vamos a predecir con el mejor modelo
bestmodel <- tune.out$best.model
summary(bestmodel)
#590 support vector - 314 son 0 y 276 son 1

pred3 <- predict(bestmodel, newdata = test_musk,type="class", decision.values = TRUE)

#Test Error - 4.69%
cm <- table(Truth=test_musk$class, Pred=pred3)
(1-sum(diag(cm))/sum(cm))*100
```


## SVM con Radial Kernel (Cost + Gamma)
```{r}
#El primer modelo de este bloque utilizamos cost = 1, y por defecto gamma es 0.5
start.time <- Sys.time()
modelSVMradial <- svm(class~., data = train_musk, type = 'C-classification', kernel = 'radial', cost=1, scale=FALSE)
(end.time <- Sys.time() - start.time) #16.37 segundos

summary(modelSVMradial) #Support vector: 794 - 465 son 0 y 329 son 1

pred <- predict(modelSVMradial, newdata = test_musk,type="class", decision.values = TRUE)
#Error de 3.13%
cm <- table(Truth=test_musk$class, Pred=pred)
(1-sum(diag(cm))/sum(cm))*100

#Eligimos directamente en seguida probar distintos valores de C con Cross Validation utilizando la función tune()
set.seed(1)
start.time <- Sys.time()
tune.out <- tune(svm,class~., data = train_musk, type = 'C-classification', kernel = 'radial',ranges=list(cost=c(0.001, 0.01, 1.5, 5, 10, 100)))
(end.time <- Sys.time() - start.time) #19.10 minutos

(bestmodel <- tune.out$best.model)
summary(bestmodel) #Support vector: 573 - 379 son 0 y 194 son 1

pred <- predict(bestmodel, newdata = test_musk,type="class", decision.values = TRUE)
#Error 2.02%
cm <- table(Truth=test_musk$class, Pred=pred)
(1-sum(diag(cm))/sum(cm))*100

#Ahora con el mejor C obtenido antes, probamos distintos valores de gamma, manteniendo cost fijo

for (gamma in 2^seq(-3,4))
{
  cat("Starting model with gamma: ",gamma)
  start.time <- Sys.time()
  model.best.c.gamma <- svm(class~., data = train_musk, type = 'C-classification', kernel = 'radial', cost=100, gamma=gamma, scale = FALSE)
  
  (pred <- predict(model.best.c.gamma, newdata = test_musk,type="class", decision.values = TRUE))
  cm <- table(Truth=test_musk$class, Pred=pred)
  error <- (1-sum(diag(cm))/sum(cm))*100
  
  cat("Error for ",gamma,"is ", error,"\n")
}
(end.time <- Sys.time() - start.time) #12.39 mins

#Starting model with gamma:  0.125 Error for  0.125 is  8.434343 
#Starting model with gamma:  0.25 Error for  0.25 is  8.787879 
#Starting model with gamma:  0.5 Error for  0.5 is  8.888889 
#Starting model with gamma:  1 Error for  1 is  8.888889 
#Starting model with gamma:  2 Error for  2 is  8.939394 
#Starting model with gamma:  4 Error for  4 is  8.939394 
#Starting model with gamma:  8 Error for  8 is  8.939394 
#Starting model with gamma:  16 Error for  16 is  8.939394

#Mismo que el cost 100 haya sido lo mejor, la combinación con gamma no ha sido buena. Creemos que no era la mejor manera de jugar con los parametros, pues entendemos que cost y gamma deben ser combinados conjuntamente para la otimización
start.time <- Sys.time()
tune.out <- tune(svm,class~., data = train_musk, type = "C-classification", kernel = "radial",ranges=list(cost=c(0.001, 0.01, 1, 1.5, 5, 10, 100),gamma=c(0.125, 0.25,0.5,1,2,4,8)))
(end.time <- Sys.time() - start.time) #Hemos tenido que terminar la ejecución pues ya tardaba 4h20min

start.time <- Sys.time()
tune.out <- tune(svm,class~., data = train_musk, type = 'C-classification', kernel = 'radial',ranges=list(cost=1,gamma=2))
(end.time <- Sys.time() - start.time)

bestmodel.radial1 <- tune.out$best.model
summary(tune.out)

pred <- predict(bestmodel.radial1, newdata = test_musk,type="class", decision.values = TRUE)
cm <- table(Truth=test_musk$class, Pred=pred)
(error <- (1-sum(diag(cm))/sum(cm))*100) #Error 
#

start.time <- Sys.time()
tune.out <- tune(svm,class~., data = train_musk, type = 'C-classification', kernel = 'radial',ranges=list(cost=0.1,gamma=0.25))
(end.time <- Sys.time() - start.time)

bestmodel.radial2 <- tune.out$best.model

pred <- predict(bestmodel.radial2, newdata = test_musk,type="class", decision.values = TRUE)
cm <- table(Truth=test_musk$class, Pred=pred)
(error <- (1-sum(diag(cm))/sum(cm))*100)

#
start.time <- Sys.time()
tune.out.radial3 <- svm(class~., data = train_musk, type = 'C-classification', kernel = 'radial',cost=0.1,gamma=0.125)
(end.time <- Sys.time() - start.time)

pred <- predict(tune.out.radial3, newdata = test_musk,type="class", decision.values = TRUE)
cm <- table(Truth=test_musk$class, Pred=pred)
(error <- (1-sum(diag(cm))/sum(cm))*100)
```

## SVM con Polynomial Kernel (Cost + Degree + Coef0)
```{r}
#It appears that the degree parameter controls the flexibility of the decision boundary. Higher degree kernels yield a more flexible decision boundary.
#degree: parameter needed for kernel of type polynomial (default: 3) - probar con 1, 2, 3 y 5
#coef0: parameter needed for kernels of type polynomial and sigmoid (default: 0)
start.time <- Sys.time()
tune.out.poly3 <- tune(svm,class~., data = train_musk, type = "C-classification", kernel = "polynomial",ranges=list(cost=c(0.001, 0.01, 1, 1.5, 5, 10, 100)),degree = 3, coef0=1)
(end.time <- Sys.time() - start.time)

(bestmodel.poly3 <- tune.out.poly3$best.model)

pred <- predict(bestmodel.poly3, newdata = test_musk,type="class", decision.values = TRUE)
cm <- table(Truth=test_musk$class, Pred=pred)
(error <- (1-sum(diag(cm))/sum(cm))*100) #Error 
#
start.time <- Sys.time()
tune.out.poly4 <- tune(svm,class~., data = train_musk, type = "C-classification", kernel = "polynomial",ranges=list(cost=c(0.001, 0.01, 1, 1.5, 5, 10, 100)),degree = 4, coef0=1)
(end.time <- Sys.time() - start.time)

(bestmodel.poly4 <- tune.out.poly4$best.model)

pred <- predict(bestmodel.poly4, newdata = test_musk,type="class", decision.values = TRUE)
cm <- table(Truth=test_musk$class, Pred=pred)
(error <- (1-sum(diag(cm))/sum(cm))*100) #Error 

#
start.time <- Sys.time()
tune.out.poly5 <- tune(svm,class~., data = train_musk, type = "C-classification", kernel = "polynomial",ranges=list(cost=c(0.001, 0.01, 1, 1.5, 5, 10, 100)),degree = 5, coef0=1)
(end.time <- Sys.time() - start.time)

(bestmodel.poly5 <- tune.out.poly5$best.model)

pred <- predict(bestmodel.poly5, newdata = test_musk,type="class", decision.values = TRUE)
cm <- table(Truth=test_musk$class, Pred=pred)
(error <- (1-sum(diag(cm))/sum(cm))*100) #Error 
```

## ROC
```{r}
#ROC Curve para el mejor Polynomial Kernel - con degree 4
#Error de Training: 
cm <- table(Truth=train_musk$class, Pred=tune.out.poly4)
(error <- (1-sum(diag(cm))/sum(cm))*100) #Error

library(ROCR)
rocplot <- function(pred,truth,...){
  predob = prediction(pred,truth)
  perf=performance(predob,"tpr","fpr")
  plot(perf,...)
}

#ROC Trainig Data
fitted = attributes(bestmodel.poly4, newdata = train_musk,type="class", decision.values = TRUE)$decision.values
par(mfrow=c(1,2))
rocplot(fitted,train_musk$class,add=T,col="red")

#ROC Test Data
fitted.test = attributes(pred)$decision.values
par(mfrow=c(1,2))
rocplot(fitted.test,train_musk$class,add=T,col="red")
```